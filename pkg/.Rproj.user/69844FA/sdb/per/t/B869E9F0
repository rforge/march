{
    "contents" : "\nmarch.mtd.h.constructEmptyMtd <- function(order,k){\n  Q <- array(0,c(k^order,k^order))\n  phi <- array(0,c(order))\n  \n  new(\"march.Mtd\",Q=Q,phi=phi,K=k,order=order)\n}\n\n# Construct nt vector, holding the number of data items per sequence (lenght of data series)\nBuildArrayNumberOfDataItems <- function(x){\n  n_rows_data <- dim(x)[1] # number of rows (number of data sequences)\n  n_cols_data <- dim(x)[2] # number of rows (number of data sequences)\n  nt <- array(0,c(1,n_rows_data)) # holds the number of data items per sequence\n  for (i in 1:n_rows_data){\n    nt[i] <- match(0,x[i,]) # first match of 0\n    if(is.na(nt[i])) nt[i] <- n_cols_data # otherwise, just the number of columns of the matrix (since if there is no 0 all positions are valid data)\n  }\n  return(nt)\n}\n\n#% Computation of the contingency table (Cg in page 385 of Berchtold, 2001)\nBuildContingencyTable <- function(y,order){\n  n_rows_data <- y@N # number of rows (number of data sequences)\n  c <- array(data=0,dim=c(order,y@K,y@K)) # crosstable (rt, Cg in page 385 of Berchtold, 2001)\n  for (g in 1:order){\n    for (i in 1:n_rows_data){\n      for (t in 1:(y@T[i]-g)){ # mc_lag is g in Berchtold, 2001\n        past <- y@y[[i]][t]\n        present <- y@y[[i]][t+g]\n        if(length((which(c(past,present)<1) | (which(c(past,present)>y@K))))==0){\n          c[g,past,present] <- c[g,past,present] + y@weights[i]\n        }\n      }\n    }\n  }\n  return(c)\n}\n\nNormalizeTable <- function(x){\n  nx <- array(NA,dim=dim(x))\n  m <- dim(x)[1]\n  sums <- rowSums(x)                                    \n  for (i in 1:m){\n    if (sums[i]!=0) nx[i,] <- x[i,]/sums[i]\n  }\t\n  return(nx)\n}\n\n#% Computation of the measure u for a crosstable\n# See p. 387 of Berchtold, 2001\nCalculateTheilU <- function(m,l,c){\n\n  u <- array(data=NA,dim=c(1,l))\n  \n  for (g in 1:l){\n    cg <- c[g,,]\n    tc <- sum(cg) # sum of elements (TCg)\n    sr <- rowSums(cg) # vector of sums of rows [Cg(.,j)]\n    sc <- colSums(cg) # vector of sums of columns [Cg(i,.)]\n    \n    # the following lines implement equation 14\n    num <- 0\n    for (i in 1:m){\n      for (j in 1:m){\n        if (cg[i,j]!=0){ # if cg[i,j], there is nothing to be added\n          num <- num + cg[i,j] * (log2(sc[i]) + log2(sr[j]) - log2(cg[i,j]) - log2(tc))\n        }\n      }\n    }\n    \n    den <- 0\n\n    for (j in 1:m){\n      if(sc[j]!=0 & tc!=0){\n        den <- den + sr[j] * (log2(sr[j]) - log2(tc))\n      }\n    }\n    \n    if(den != 0) u[g] = num/den\n    else u[g] = NaN\n    \n  }\n  return(u)  \n}\n\nInitializeParameters <- function(u,init_method,c,is_mtdg,m,order){\n  # Initialization of the lag parameters (Eq. 15 of Berchtold, 2001)\n  phi <- u/(sum(u)) # TODO : Supprimer la division pour coller a march\n  if (is_mtdg){ \n    q <- array(NA,c(order,m,m))\n    for (g in 1:order){\n      q[g,,] <- NormalizeTable(c[g,,])\n    }\n    return(list(phi=phi,q=q))\n  } else {\n    # Initialization of the initial matrix Q (see page 387 of Berchtold, 2001)\n    if (init_method == \"weighted\"){\n      # Initialization of Q as a weighted sum of matrices Q1,...,Ql\n      q_tilde <- array(0,dim=c(1,m,m))\n      for (g in 1:order){\n        q_tilde[1,,] <- q_tilde[1,,] + phig[g] * c[g,,]\n      }\n      q <- NormalizeTable(q_tilde)\n    } else if (init_method == \"best\"){\n      # Initialization of Q as Q=Qk where k = argmax(ug)\n      k <- which.max(u)\n      q <- array(0,c(1,m,m))\n      q[1,,] <- NormalizeTable(c[k,,])\n    } else if (init_method == \"random\"){\n      # Initialization of Q as a random matrix\n      q <- 0.1 + array(runif(m*m),c(1,m,m))\n      q[1,,] <- q/rowSums(q[1,,])\n    } else{\n      stop(\"Init parameter should be either, \\\"best\\\", \\\"random\\\" or \\\"weighted\\\"\",call.=FALSE)\n    }\n    return(list(phi=phi,q=q))\n  }\n}\n\n# Construct the array i0_il with all possible combinations of states 1...m in a time window of size l+1\nBuildArrayCombinations <- function(m,l){\n  i0_il <- array(0,c(m^(l+1),l+1))\n  values <- 1:m\n  for(i in 1:(l+1)){\n    i0_il[,i] <- t(kronecker(values,rep(1,m^(l+1)/m^i)))\n    values <- kronecker(rep(1,m),values)\n  }\n  return(i0_il)\n}\n\n# Construct array n_i0_il where n_i0_il[i0,...il] is the number of sequences of the form X(t-l)=il,...,X(t)=i0\nBuildArrayNumberOfSequences <- function(y,order){\n  n_i0_il <- array(0,dim=rep(y@K,order+1))\n  for(i in 1:y@N){\n    for(t in march.h.seq(1,y@T[i]-order)){\n      ind <- y@y[[i]][t:(t+order)]\n      n_i0_il[rbind(ind)] <- n_i0_il[rbind(ind)] + 1\n    }\n    \n  }\n  # Transform to a one-dimensional array\n  n_i0_il <- c(n_i0_il)\n  return(n_i0_il)\n}\n\n# Transform transition matrix q in such a way that the log-likelihood (Eq. 6) and the partial derivatives (equations in page 382) are easy to calculate\nBuildArrayQ <- function(m,l,i0_il,n_i0_il,q){\n  q_i0_il <- array(0,c(m^(l+1),l))\n  for (j in 1:length(n_i0_il)){\n    if( dim(q)[1]>1){\n      for (g in 1:l){\n        q_i0_il[j,g] <- q[g,i0_il[j,g+1],i0_il[j,1]]\n      }\n    }\n    else {\n      for (k in 1:l){\n        q_i0_il[j,k] <- q[1,i0_il[j,k+1],i0_il[j,1]] \n      }\n    }\n  }\n  return(q_i0_il)\n}\n\nCalculateLogLikelihood <- function(n_i0_il,q_i0_il,phi){\n  ll <- 0\n  for (i in 1:length(n_i0_il)){\n    if(n_i0_il[i] > 0){\n      ll <- ll + n_i0_il[i] * log(q_i0_il[i,] %*% t(phi) )\n    }\n  }\n  ll\n}\n\n# Calculate the partial derivatives of log(L) with respect to phi_k (page 382) \nPartialDerivativesPhi <- function(n_i0_il,q_i0_il,l,phi){\n  pd_phi <- rep(0,l)\n  for (i in 1:length(n_i0_il)){\n    for (g in 1:l){\n      if (n_i0_il[i] > 0 && (q_i0_il[i,] %*% t(phi)) != 0){\n        pd_phi[g] <- pd_phi[g] + n_i0_il[i] * q_i0_il[i,g] / (q_i0_il[i,] %*% t(phi))\n      }   \n    }\n  }\n  return(pd_phi)\n}\n\n# Calculate the partial derivatives of log(L) with respect to q_ik_i0 (page 382) \nPartialDerivativesQ <- function(n_i0_il,i0_il,q_i0_il,m,phi,order){\n  pd_q <- array(0,dim=c(m,m))\n  for (i in 1:length(n_i0_il)){\n    for (j in 1:order){\n      if (n_i0_il[i] > 0 && (q_i0_il[i,] %*% t(phi)) != 0){\n        pd_q[i0_il[i,j+1],i0_il[i,1]] <- pd_q[i0_il[i,j+1],i0_il[i,1]] + n_i0_il[i] * phi[j] / ( q_i0_il[i,] %*% t(phi) )\n      }\n    }\n  }\n  return(pd_q)\n}\n\nOptimizePhi <- function(phi,pd_phi,delta,is_constrained,delta_stop,ll,n_i0_il,q_i0_il){\n  \n  delta_it <- delta[1]\n  \n  i_inc <- which.max(pd_phi) # index of the phi parameter to increase (the one corresponding to the largest derivative)\n  i_dec <- which.min(pd_phi) # index of the phi parameter to decrease (the one corresponding to the smallest derivative)\n  par_inc <- phi[i_inc]\n  par_dec <- phi[i_dec]\n  \n  if (is_constrained){\n    \n    if (par_inc == 1){ # \"If phi_plus = 1, this parameter cannot be increased and the algorithm cannot improve the log-likelihood through a reestimation of the vector phi\" (page 382)\n      # \"If the distribution was not reevaluated because the parameter to increase was already set to 1, delta is not changed.\" (page 383)\n      return(list(phi=phi,ll=ll,delta=delta))\n    }\n    #if ( par_inc + delta_it > 1){ # \"If phi_plus + delta > 1, the quantity delta is too large and it must be set to delta = 1 - phi_plus.\" (page 382)\n    #    delta_it <- 1 - par_inc\n    #}\n    if ( par_dec == 0 ){ # \"If phi_minus = 0, this parameter cannot be decreased. Then, we decrease the parameter corresponding to the smallest strictly positive derivative\"\n      pd_phi_sorted <- sort(pd_phi,index.return=TRUE)\n      i_dec <- pd_phi_sorted$ix[min(which(phi[pd_phi_sorted$ix]>0))]\n      par_dec <- phi[i_dec]\n    }\n    #if ( par_dec - delta_it < 0){ # \"If phi_minus - delta < 0, the quantity delta is too large and it must be set to delta = 1 - phi_minus.\"\n    #    delta_it <- 1 - par_dec\n    #}\n    delta_it <- min(c(delta_it,1-par_inc,par_dec))\n  }\n  \n  new_phi <- phi\n  \n  while(TRUE){\n    new_phi[i_inc] <- par_inc + delta_it\n    new_phi[i_dec] <- par_dec - delta_it\n    if (!is_constrained){ # constraints Eq. 4 Berchtold, 2001 p. 380\n      t <- sum(new_phi[new_phi >= 0])\n      for (i in 1:k){\n        q_min <- min(q[i,])\n        q_max <- max(q[i,])\n        if (t*q_min + (1-t)*q_max < 0){\n          return(list(phi=new_phi,ll=new_ll,delta=delta))\n        }\n      }\n    }\n    new_ll <- CalculateLogLikelihood(n_i0_il,q_i0_il,new_phi) # \"Once the new vector phi is known, we can compute the new log-likelihood of the model.\" (page 382) \n    if (new_ll > ll){ # \"If it is larger than the previous value, the new vector phi is accepted and the procedure stops.\" (page 382)\n      if (delta_it == delta[1]){ # \"If the distribution was reevaluated with the original value of delta [...], delta is set to 2*delta\" (page 383)\n        delta[1] <- 2*delta[1]\n      } # \"if the distribution was reevaluated with a value of delta smaller than its value at the beginning of Step 2, delta keeps its present value\"\n      return(list(phi=new_phi,ll=new_ll,delta=delta))  \n    } else { # In the other case, delta is divided by 2 and the procedure iterates\n      if (delta_it <= delta_stop) { # \"When delta becomes smaller than a fixed threshold, we stop the procedure, even if phi was not reevaluated\"\n        delta[1] <- 2*delta[1] # \"If the algorithm was completed without reestimation, delta is set to twice the value reached at the end of Step 2\"\n        return(list(phi=phi,ll=ll,delta=delta))  \n      }\n      delta_it <- delta_it/2\n    }   \n  }\n  \n}\n\nOptimizeQ <- function(q,j,pd_q,delta,delta_stop,ll,n_i0_il,q_i0_il,phi,i0_il,k,l,g){\t\n  delta_it <- delta[j+1]\n  \n  i_inc <- which.max(pd_q[j,]) # index of the phi parameter to increase (the one corresponding to the largest derivative)\n  i_dec <- which.min(pd_q[j,]) # index of the phi parameter to decrease (the one corresponding to the smallest derivative)\n  par_inc <- q[g,j,i_inc]\n  par_dec <- q[g,j,i_dec]\n  \n  if (par_inc == 1){ # \"If phi_plus = 1, this parameter cannot be increased and the algorithm cannot improve the log-likelihood through a reestimation of the vector phi\" (page 382)\n    # \"If the distribution was not reevaluated because the parameter to increase was already set to 1, delta is not changed.\" (page 383)\n    return(list(q=q,q_i0_il=q_i0_il,ll=ll,delta=delta))\n  }\n  #if ( par_inc + delta_it > 1){ # \"If phi_plus + delta > 1, the quantity delta is too large and it must be set to delta = 1 - phi_plus.\" (page 382)\n  #   delta_it <- 1 - par_inc\n  #}\n  if ( par_dec == 0 ){ # \"If phi_minus = 0, this parameter cannot be decreased. Then, we decrease the parameter corresponding to the smallest strictly positive derivative\"\n    pd_q_sorted <- sort(pd_q[j,],index.return=TRUE)\n    i_dec <- pd_q_sorted$ix[min(which(q[g,j,pd_q_sorted$ix]>0))]    \n    par_dec <- q[g,j,i_dec]\n  }\n  #if ( par_dec - delta_it < 0){ # \"If phi_minus - delta < 0, the quantity delta is too large and it must be set to delta = 1 - phi_minus.\"\n  #    delta_it <- 1 - par_dec\n  #}\n  \n  delta_it <- min(c(delta_it,1-par_inc,par_dec))\n  \n  new_q_row <- q[g,j,]\n  \n  while(TRUE){\n    new_q_row[i_inc] <- par_inc + delta_it\n    new_q_row[i_dec] <- par_dec - delta_it\n    new_q <- q\n    new_q[g,j,] <- new_q_row\n    new_q_i0_il <- BuildArrayQ(k,l,i0_il,n_i0_il,new_q)\n    new_ll <- CalculateLogLikelihood(n_i0_il,new_q_i0_il,phi) # \"Once the new vector phi is known, we can compute the new log-likelihood of the model.\" (page 382) \n    if (new_ll > ll){ # \"If it is larger than the previous value, the new vector phi is accepted and the procedure stops.\" (page 382)\n      if (delta_it == delta[j+1]){ # \"If the distribution was reevaluated with the original value of delta [...], delta is set to 2*delta\" (page 383)\n        delta[j+1] <- 2*delta[j+1] \n      } # \"if the distribution was reevaluated with a value of delta smaller than its value at the beginning of Step 2, delta keeps its present value\" \n      return(list(q=new_q,q_i0_il=new_q_i0_il,ll=new_ll,delta=delta))\n    } else { # In the other case, delta is divided by 2 and the procedure iterates\n      if (delta_it <= delta_stop) { # \"When delta becomes smaller than a fixed threshold, we stop the procedure, even if phi was not reevaluated\"\n        delta[j+1] <- 2*delta[j+1] # \"If the algorithm was completed without reestimation, delta is set to twice the value reached at the end of Step 2\"\n        return(list(q=q,q_i0_il=q_i0_il,ll=ll,delta=delta))  \n      }\n      delta_it <- delta_it/2\n    }   \n  }\n  \n}\n\n#' Construct a Mixture Transition Distribution (MTD) model.\n#' \n#' A Mixture Transition Distribution model (\\code{\\link{march.Mtd}}) object of order \\emph{order} is constructed\n#' according to a given \\code{\\link{march.Dataset}} \\emph{y}, truncated from the first \\emph{maxOrder}-\\emph{order} \n#' elements of each sequence in order to return a model\n#' which can be compared with other Markovian model of visible order maxOrder. \n#' \n#' @param y the dataset (\\code{\\link{march.Dataset}}) on which construct the model.\n#' @param order the order of the constructed model.\n#' @param maxOrder the maximum visible order among the set of Markovian models to compare.\n#' @param mtdg is the constructed model a MTDg, that uses several transition matrices (value: \\emph{TRUE} or \\emph{FALSE}).\n#' @param init the init method, to choose among \\emph{best}, \\emph{random} and \\emph{weighted}.\n#' @param deltaStop the delta below which the optimization phases of phi and Q stop.\n#' @param llStop the ll increase below which the EM algorithm stop.\n#' @param maxIter \n#' \n#' @author Ogier Maitre\n#' @example examples/march.mtd.construct.example.R\n#' @seealso \\code{\\link{march.Mtd}}, \\code{\\link{march.Model}}, \\code{\\link{march.Dataset}}.\n#' @export\nmarch.mtd.construct <- function(y,order,maxOrder=order,mtdg=FALSE,init=\"best\", deltaStop=0.0001, llStop=0.01, maxIter=0){\n \n  order <- march.h.paramAsInteger(order)\n  maxOrder <- march.h.paramAsInteger(maxOrder)\n  \n  if( order>maxOrder ){\n    stop(\"maxOrder should be greater or equal than order\")\n  }\n  \n  ySave <- y\n  \n  # here we create a new data set by truncating the first (maxOrder-order+1) element\n  # this data set will be used to construct the mtd model, instead of the original one.\n#   for( i in 1:y@N ){\n#     y@y[[i]] <- y@y[[i]][(maxOrder-order+1):length(y@y[[i]])]\n#     y@T[i] <- length(y@y[[i]])\n#   }\n  \n  y <- march.dataset.h.filtrateShortSeq(y,maxOrder+1)\n  y <- march.dataset.h.cut(y,maxOrder-order)\n  \n  is_constrained <- TRUE # if FALSE the model is unconstrained and the constraints given by Eq. 4 are activated instead of those given by Eq. 3 (Berchtold, 2001, p. 380)\n  is_mtdg <- mtdg\n  init_method <- init\n    \n  # 1.1. Choose initial values for all parameters\n  # nt <- BuildArrayNumberOfDataItems(y) This is no longer needed, as y now contains the T field\n  c <- BuildContingencyTable(y,order)\n  u <- CalculateTheilU(y@K,order,c)\n  init_params <- InitializeParameters(u=u,init_method=init_method,c=c,is_mtdg=is_mtdg,m=y@K,order=order)\n  phi <- init_params$phi\n  q <- init_params$q\n  \n\n  # 1.2. Choose a value for delta and a criterion to stop the algorithm\n  delta <- array(0.1,dim=c(1,y@K+1)) # a different delta is used for each of the m+1 sets of parameters (vector phi + each row of the transition matrix Q)\n  delta_stop <- deltaStop\n  ll_stop <- llStop\n \n  # 2. Iterations\n  # 2.1. Reestimate the vector phi by modifying two of its elements\n  # 2.2. Reestimate the transition matrix Q by modifying two elements of each row\n  \n  # 3. End criterion\n  # 3.1. If the increase of the LL since the last iteration is greater than the stop criterion, go back to step 2\n  # 3.2. Otherwise, end the procedure\n  \n  i0_il <- BuildArrayCombinations(y@K,order)\n  n_i0_il <- BuildArrayNumberOfSequences(y,order)\n  q_i0_il <- BuildArrayQ(m=y@K,l=order,i0_il=i0_il,n_i0_il = n_i0_il,q=q)\n  new_ll <- CalculateLogLikelihood(n_i0_il=n_i0_il,q_i0_il=q_i0_il,phi=phi)\n\n  iter <- 0\n  while (TRUE){\n    if( maxIter>0 && iter>=maxIter ){ break }\n    else{ iter <- iter+1 }\n   \n    \n    ll <- new_ll\n    # \"Reestimate the vector phi by modifying two of its elements.\" (p. 383)\n    pd_phi <- PartialDerivativesPhi(n_i0_il=n_i0_il,q_i0_il=q_i0_il,l=order,phi = phi)\n    res_opt_phi <- OptimizePhi(phi=phi,pd_phi=pd_phi,delta=delta,is_constrained=is_constrained,delta_stop=delta_stop,ll=ll,n_i0_il=n_i0_il,q_i0_il=q_i0_il)\n    phi <- res_opt_phi$phi\n    new_ll <- res_opt_phi$ll\n    delta <- res_opt_phi$delta\n \n    \n    # \"Reestimate the transition matrix Q by modifying two elements of each row.\" (p. 383)\n    for (j in 1:y@K){\n      qTmp <- array(NA,c(dim(q)[1],y@K,y@K))\n      llTmp <- array(NA,c(dim(q)[1]))\n      pd_q <- PartialDerivativesQ(n_i0_il,i0_il,q_i0_il,y@K,phi=phi,order=order)\n      \n      # w.r.t. the partial derivative, find which matrix q_g should be modified \n      for( g in 1:dim(q)[1] ){\n        res_opt_q <- OptimizeQ(q=q,j=j,pd_q=pd_q,delta=delta,delta_stop=delta_stop,ll=new_ll,n_i0_il=n_i0_il,q_i0_il=q_i0_il,phi=phi,i0_il = i0_il,k=y@K,l=order,g=g)\n        qTmp[g,,] <- res_opt_q$q[g,,]\n        q_i0_il <- res_opt_q$q_i0_il\n        llTmp[g] <- res_opt_q$ll\n        delta <- res_opt_q$delta\n      }\n      # use the one maximizing the ll\n      llMaxId <- which.max(llTmp)\n      q[llMaxId,,] <- qTmp[llMaxId,,]\n    }\n    new_ll <- llTmp[llMaxId]\n    if (new_ll - ll < ll_stop){ break }\n  }\n  \n  nbZeros <- length(which(q==0))+length(which(phi==0))\n  \n  # construct and return the final object.\n  new(\"march.Mtd\",order=order,Q=q,phi=phi,ll=ll,y=ySave,dsL=sum(y@T-order),nbZeros=nbZeros)\n}",
    "created" : 1392903457712.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2136290890",
    "id" : "B869E9F0",
    "lastKnownWriteTime" : 1394359741,
    "path" : "~/Desktop/Bur/mc-RC3/mc/R/march.mtd.R",
    "project_path" : "R/march.mtd.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}